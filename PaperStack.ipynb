{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "id": "33YuE0OwFuZo"
      },
      "outputs": [],
      "source": [
        "#@markdown #**Welcome to PaperStack!**\n",
        "\n",
        "#@markdown ### **What is PaperStack?**\n",
        "#@markdown PaperStack is a **multi-agent AI pipeline** for **automated document generation**.\n",
        "#@markdown It demonstrates how specialized AI agents can work together to produce **structured, domain-specific writing**—whether for research papers, technical reports, or other formal documents.\n",
        "\n",
        "#@markdown This notebook is an **experiment in automation**, not an attempt to generate human-quality academic work.\n",
        "#@markdown Instead, it provides a **transparent and modular** way to observe and tweak how AI systems compose structured content step by step.\n",
        "#@markdown Since all outputs are fully AI-generated, they are **not attributable to any person or entity**.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown #**How It Works**\n",
        "\n",
        "#@markdown ### **1. User Input**\n",
        "\n",
        "#@markdown Once the user inputs a topic, the AI pipeline progresses through a structured sequence of tasks to produce, refine, and format the document.\n",
        "\n",
        "#@markdown ### **2. AI Pipeline Overview**\n",
        "#@markdown PaperStack operates through a structured multi-agent process, ensuring systematic content generation.\n",
        "\n",
        "#@markdown **Task-Specific System Prompts**\n",
        "#@markdown - Each AI agent is assigned a specialized role, receiving structured prompts tailored to its function within the pipeline. These task-specific instructions ensure focused execution at each stage.\n",
        "\n",
        "#@markdown **Strict Formatting Guidelines for Outputs (JSON)**\n",
        "#@markdown - Al output content adheres to standardized **JSON formatting**, maintaining consistency and ensuring compatibility for further processing.\n",
        "\n",
        "#@markdown **Dual-Layer JSON Validation**\n",
        "#@markdown - Generated JSON responses undergo **automated validation** to check for structural and syntactical correctness. If JSON parsing fails, the result is passed to a **LLM JSON fixing agent** to correct errors. This loop repeats until parsing is successul and the result is passed to the next agent in the pipeline.\n",
        "\n",
        "#@markdown **Drafting and Paragraph-Level Revisions**\n",
        "#@markdown - The system first drafts the document, then performs **paragraph-by-paragraph revisions**, enhancing clarity, coherence, and logical flow.\n",
        "\n",
        "#@markdown **Section Scanning and Coherence Revisions**\n",
        "#@markdown - After paragraph-level refinements, each section is analyzed for **coherence** and **repetition**. A separate AI agent provides targeted revision instructions for each to ensure logical consistency and reduce redundancy across the document.\n",
        "\n",
        "#@markdown **Attribution Scanning and Citation Insertion**\n",
        "#@markdown - The system scans the document to identify statements requiring attribution. Where necessary, citations are inserted in a structured format to maintain proper referencing.\n",
        "\n",
        "#@markdown **Abstract Generation**\n",
        "#@markdown - A summarization step creates a **concise abstract**, distilling the core arguments and conclusions of the document.\n",
        "\n",
        "#@markdown **Formatting for Printing**\n",
        "#@markdown - The final document is structured for readability and prepared for output in a format suitable for review."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##**Future Plans**\n",
        "#@markdown\n",
        "#@markdown - Add more fields for user inputs, including:\n",
        "#@markdown   - Additional context to guide the AI's understanding\n",
        "#@markdown   - Additional fields of study\n",
        "#@markdown   - Key points or arguments the user wants included\n",
        "#@markdown   - User prompted hypotheses, methodology, data, and results\n",
        "#@markdown   - Preferred philosophical frameworks or schools of thought\n",
        "#@markdown   - Specific philosophers or works to reference\n",
        "#@markdown   - Citation style preferences\n",
        "#@markdown   - Option to include particular counterarguments or opposing views, and how to address them\n",
        "#@markdown   - Writing style preference (academic, accessible, narrative)\n",
        "#@markdown\n",
        "#@markdown - Refine and improve the attribution scanner\n",
        "#@markdown - Link to a database of works like Google Scholar and field-specific OAI-PMH databases to validate works cited\n",
        "#@markdown - Incorporate specialized fine-tuned models for editing, revision, in-text attribution, and citation\n",
        "#@markdown - Transfer to a web UI for improved UX"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Re18AN1WjR8I"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "h5PS324xbNL7"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown # **Getting Started**\n",
        "\n",
        "#@markdown ###**Step 1: Get your API key.**\n",
        "\n",
        "#@markdown PaperStack requires a **Together AI API Key** to generate content using the **Llama-3.3-70B-Instruct-Turbo-free** model.\n",
        "\n",
        "\n",
        "#@markdown - Visit [**Together AI**](https://together.ai) and sign up or log in.\n",
        "#@markdown - Navigate to **API Keys** in your account settings.\n",
        "#@markdown - Click **Generate New Key**, then copy it.\n",
        "\n",
        "#@markdown   ### **Step 2. Store Your API Key in Google Colab**\n",
        "#@markdown - In the **left sidebar menu**, click the **key** icon .\n",
        "#@markdown - Click **\"Add a new secret\"**.\n",
        "#@markdown - In the **\"Name\"** field, enter:\n",
        "#@markdown   `TogetherAPI`\n",
        "#@markdown - In the **\"Value\"** field, paste your **API key**.\n",
        "#@markdown - Toggle **\"Notebook access\"** to **ON**.\n",
        "#@markdown - Press the  ▶ in the upper left corner of this cell.\n",
        "\n",
        "#@markdown This notebook ensures **API key security** using Google Colab's **Secrets** feature.\n",
        "#@markdown - API keys are **never displayed in outputs** or stored in the notebook.\n",
        "#@markdown - If the notebook is **copied, shared, or downloaded**, **API keys do not transfer**.\n",
        "#@markdown - Users must re-enter API credentials each session for security.\n",
        "#@markdown\n",
        "#@markdown For more information on how the Secrets feature works in Colab, refer to:\n",
        "#@markdown [How to Use Secrets in Google Colab](https://medium.com/@parthdasawant/how-to-use-secrets-in-google-colab-450c38e3ec75)\n",
        "\n",
        "%%capture\n",
        "!pip install together\n",
        "!pip install pylatex\n",
        "!apt-get install -y texlive texlive-latex-extra texlive-xetex\n",
        "from pylatex import Document, Section, NoEscape, Command\n",
        "from google.colab import userdata, files\n",
        "from together import Together\n",
        "from IPython.display import Markdown, display\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "KEY = userdata.get('TogetherAPI')\n",
        "client = Together(api_key = KEY)\n",
        "\n",
        "CACHE_FILE = \"essay_cache.json\"\n",
        "\n",
        "def save_cache(data):\n",
        "    \"\"\"Saves the current state of essay generation to a JSON cache.\"\"\"\n",
        "    with open(CACHE_FILE, \"w\") as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "\n",
        "def load_cache():\n",
        "    \"\"\"Loads cached essay generation progress.\"\"\"\n",
        "    if os.path.exists(CACHE_FILE):\n",
        "        with open(CACHE_FILE, \"r\") as f:\n",
        "            return json.load(f)\n",
        "    return {}\n",
        "\n",
        "def clear_cache():\n",
        "    \"\"\"Clears the essay generation cache.\"\"\"\n",
        "    if os.path.exists(CACHE_FILE):\n",
        "        os.remove(CACHE_FILE)\n",
        "        print(\"Cache cleared.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## **Step 2: Set the Max JSON fixing attempts.**\n",
        "\n",
        "#@markdown Part of what makes PaperStack's AI agent pipeline robust is the JSON fixing agent, which ensures that each agent's output can be broken down and interpreted correctly. If the parsing fails, the JSON fixing agent will try to fix it and put it back into the pipeline. This operation loops until the output is fixed, or the maximum number of attempts is reached. Parsing errors are rare, and fixing usually works on the first try. However, it's possible that an error could persist and stall the pipeline indefinitely. To prevent that, you can set the maximum number of attepts here.\n",
        "\n",
        "MAX_JSON_ATTEMPTS = 5 #@param {\"type\":\"integer\", \"placeholder\":\"Maximum number of times the JSON fixing agent should try\"}\n",
        "\n",
        "#@markdown After you set the maximum, press the ▶ in the upper left corner of this cell."
      ],
      "metadata": {
        "cellView": "form",
        "id": "XMj-ilRgkxvT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "h9GI8JHGbHyT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "91064f74-d6f7-4a71-a90e-8e45fa9c11e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cached essay...\n",
            "\n",
            "Outputting essay...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_172ac9e7-aca0-4d0d-a81d-1750835703da\", \"essay.pdf\", 155968)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF compiled successfully: essay.pdf\n"
          ]
        }
      ],
      "source": [
        "#@markdown ## **Step 3: Generate the Paper.**\n",
        "\n",
        "#@markdown Type your topic in the field below. PaperStack performs best with specific and well-posed questions or detailed suggestions that are rich enough to be discussed at length. Vague, broad, or simple topics tend to produce lower quality results with a high degree of repitition.\n",
        "\n",
        "Topic = \"The phenomenological implications of the control scheme of \\\"getting over it with Bennet Foddy\\\", i.e., how it subverts C. Thi. Nguyen's aesthetic beauty of games through the lens of Merleau-Ponty philosophy and the anatomy and physiology of human hands. \" #@param {\"type\":\"string\", \"placeholder\":\"Type the topic or title\"}\n",
        "\n",
        "#@markdown Choose output format:\n",
        "format_choice = \"PDF\"  #@param [\"PDF\", \"plain text\", \"markdown\", \"LaTeX\"]\n",
        "\n",
        "#@markdown Choose Output method (PDF can *only* be saved to file):\n",
        "\n",
        "method_choice = \"save to file\" #@param [\"display\", \"save to file\"]\n",
        "\n",
        "#@markdown Press the ▶ in the upper left corner of this cell to generate the paper. This could take 8-12 minutes, so please be patient.\n",
        "\n",
        "def call_llm(prompt, system_prompt):\n",
        "    \"\"\"\n",
        "    General function to call the LLM with a system prompt and user input.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=None,\n",
        "        temperature=0.7,\n",
        "        top_p=0.7,\n",
        "        top_k=50,\n",
        "        repetition_penalty=1,\n",
        "        stop=[\"<|eot_id|>\", \"<|eom_id|>\"],\n",
        "        stream=False\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def context_agent(topic):\n",
        "    system_prompt = (\n",
        "        \"You are a philosophy researcher specializing in historical and conceptual analysis in the field of philosophy. Your task is to identify key philosophical works, \"\n",
        "        \"thinkers, and concepts relevant to the given topic and summarize their relevance in relation to the relevant arguments and concepts. \"\n",
        "        \"Your response must be formatted strictly as JSON and contain no extra text or explanations.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Provide context for the following topic:\n",
        "    {topic}\n",
        "\n",
        "    Your response must be formatted as a JSON object with the following structure:\n",
        "    {{\n",
        "      \"philosophers\": [\n",
        "        {{\n",
        "          \"name\": \"string\",\n",
        "          \"work\": \"string\",\n",
        "          \"relevance\": \"string\"\n",
        "        }}\n",
        "      ],\n",
        "      \"concepts\": [\n",
        "        {{\n",
        "          \"name\": \"string\",\n",
        "          \"definition\": \"string\",\n",
        "          \"relevance\": \"string\"\n",
        "        }}\n",
        "      ]\n",
        "    }}\n",
        "\n",
        "    - Ensure at least two philosophers and two concepts are included.\n",
        "    - Explanations must be concise yet specific, directly connecting each philosopher and concept to the topic.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def thesis_agent(topic, context):\n",
        "    system_prompt = (\n",
        "        \"You are a philosophy professor specializing in academic philosophical writing. Your task is to generate a strong, clear, and well-reasoned thesis statement on the given topic using the context provided. \"\n",
        "        \"The thesis should be debatable, precise, and philosophically rigorous.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Generate a thesis statement for the following topic:\n",
        "    Topic: {topic}\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "    Your response must be formatted as a JSON object with the following structure:\n",
        "    {{\n",
        "      \"thesis\": \"string\"\n",
        "    }}\n",
        "\n",
        "    Ensure the thesis is concise (one or two sentences) and presents a clear position that can be logically argued.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "\n",
        "def argument_agent(thesis):\n",
        "    system_prompt = (\n",
        "        \"You are a formal logician. Your task is to construct a rigorous philosophical argument in support of the given thesis. \"\n",
        "        \"Your response must follow formal logical principles, ensuring clear premises that lead to a reasoned conclusion. \"\n",
        "        \"Additionally, you must present a counterargument and a refutation of that counterargument. \"\n",
        "        \"Your output must conform to JSON structure with no additional text, comments, characters, markdown beginning with { and \"\n",
        "        \"ending with }\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Construct a structured argument based on the following thesis:\n",
        "    {thesis}\n",
        "\n",
        "    Your response must be formatted as a JSON object:\n",
        "\n",
        "    {{\n",
        "      \"argument\": {{\n",
        "        \"premises\": [\n",
        "          \"string\"\n",
        "        ],\n",
        "        \"conclusion\": \"string\"\n",
        "      }},\n",
        "      \"counterargument\": {{\n",
        "        \"premises\": [\n",
        "          \"string\"\n",
        "        ],\n",
        "        \"conclusion\": \"string\"\n",
        "      }},\n",
        "      \"refutation\": \"string\"\n",
        "    }}\n",
        "\n",
        "    Do not include any additional text before or after the JSON response. Do not include any markdown or other formatting. Only ouput the text of the JSON.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def discussion_agent(argument,context):\n",
        "    system_prompt = (\n",
        "        \"You are a philosophy seminar leader facilitating an advanced discussion on the given argument in a graduate-level philosophy course. \"\n",
        "        \"Your task is to generate a set of meaningful philosophical questions and accompanying exposition that critically explore, expand, and challenge the argument.\"\n",
        "        \"You and the other participants in the philosophy seminar have familiarized yourselves with the context.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Discuss the following arguments in the appropriate context:\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Arguments:\n",
        "    {argument}\n",
        "\n",
        "    Your response must be formatted as a JSON object with the following structure:\n",
        "    {{\n",
        "      \"questions\": [\n",
        "        {{\n",
        "          \"id\": \"integer\",\n",
        "          \"content\": \"string\",\n",
        "          \"answer\": \"string\",\n",
        "          \"category\": \"string\"\n",
        "        }}\n",
        "      ]\n",
        "    }}\n",
        "\n",
        "    Each question should be categorized under one of the following:\n",
        "    - \"validity\" (questions about logical structure and consistency)\n",
        "    - \"soundness\" (questions about the truth of premises)\n",
        "    - \"alternative perspectives\" (questions that explore different viewpoints)\n",
        "    - \"implications\" (questions about consequences of accepting the argument)\n",
        "\n",
        "    Keep questions open-ended and specific enough to guide meaningful discussion, ensuring clarity and coherence.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def overview_agent(thesis, arguments, context, discussion):\n",
        "    system_prompt = (\n",
        "      \"\"\"You are an academic writer specializing in structuring philosophical essays for maximum clarity, coherence, and intellectual depth. Your task is to generate a comprehensive and well-organized overview of the provided reference materials for a major academic work.\n",
        "\n",
        "      The overview should not merely summarize each section but should reconstruct the content into a logically structured and compelling exposition of the central themes, arguments, and discussions.\n",
        "\n",
        "      Your overview should:\n",
        "\n",
        "      - Present the topic, thesis, and core arguments in a clear and logically progressive manner.\n",
        "      - Synthesize key ideas, discussions, and counterarguments into a cohesive narrative.\n",
        "      - Reorganize content if necessary to enhance clarity, argumentative strength, and thematic development.\n",
        "      - Ensure fluid transitions between concepts and sections to guide the reader effectively.\n",
        "      - Capture nuance, theoretical depth, and the broader implications of the discussion.\"\"\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Generate an essay overview based on the following:\n",
        "\n",
        "    Thesis:\n",
        "    {thesis}\n",
        "\n",
        "    Arguments:\n",
        "    {arguments}\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Discussion:\n",
        "    {discussion}\n",
        "\n",
        "    Your response must be formatted as a JSON object with the following structure:\n",
        "    {{\n",
        "      \"overview\": \"string\",\n",
        "      \"sections\": [\n",
        "        {{\n",
        "          \"title\": \"string\",\n",
        "          \"summary\": \"string\"\n",
        "        }}\n",
        "      ]\n",
        "    }}\n",
        "\n",
        "    - The \"overview\" field should contain a 2-3 sentence high-level summary of the essay.\n",
        "    - The \"sections\" array should include each major section of the essay, with a brief summary of its purpose and content.\n",
        "    - Ensure clarity, coherence, and proper structuring.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def structure_agent(overview):\n",
        "    system_prompt = (\n",
        "        \"You are an academic writing strategist in the field of philosophy leading a team of professional philosophers \"\n",
        "        \"in the authorship of an academic paper. Your task is to create a structured outline for a philosophy essay \"\n",
        "        \"based on the provided overview. The outline must be logically structured, ensuring coherence and flow. However, \"\n",
        "        \"the structure need not follow the input structure. Rather, the structure should optimally present the thesis in a \"\n",
        "        \"logical and cohesive progression of detailed academic exposition and discussion to present and discuss the topic\"\n",
        "        \"purpose of drawing meaningful conclusions regarding the thesis. \"\n",
        "        \"It should be formatted as a JSON object that can be parsed programmatically.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Generate a structured outline for the following essay overview:\n",
        "\n",
        "    {overview}\n",
        "\n",
        "    Your response must be formatted as a JSON object with the following structure:\n",
        "    {{\n",
        "      \"title\": \"string\",\n",
        "      \"sections\": [\n",
        "        {{\n",
        "          \"title\": \"string\",\n",
        "          \"summary\": \"string\",\n",
        "          \"paragraphs\": [\n",
        "            {{\n",
        "              \"id\": \"integer\",\n",
        "              \"topic\": \"string\",\n",
        "              \"details\": \"string\"\n",
        "            }}\n",
        "          ]\n",
        "        }}\n",
        "      ]\n",
        "    }}\n",
        "\n",
        "    - The \"title\" field should contain the title of the essay.\n",
        "    - Each \"sections\" object should include a section title and a brief summary of its purpose.\n",
        "    - Each section should contain a \"paragraphs\" array with numbered paragraph entries, including a topic and a description of what it should cover.\n",
        "    - Ensure that the outline provides a logical flow from introduction to conclusion.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def split_paragraph(paragraph_text):\n",
        "    \"\"\"Splits a paragraph into sentences while avoiding splitting after common abbreviations.\"\"\"\n",
        "    if not paragraph_text.strip():\n",
        "        return []  # Return empty list for empty input\n",
        "\n",
        "    # Define common abbreviations that should not cause sentence splits\n",
        "    abbreviations = {\n",
        "        \"Dr.\": \"Dr<abbr>\",\n",
        "        \"Mr.\": \"Mr<abbr>\",\n",
        "        \"Ms.\": \"Ms<abbr>\",\n",
        "        \"Mrs.\": \"Mrs<abbr>\",\n",
        "        \"Jr.\": \"Jr<abbr>\",\n",
        "        \"Sr.\": \"Sr<abbr>\",\n",
        "        \"vs.\": \"vs<abbr>\",\n",
        "        \"etc.\": \"etc<abbr>\",\n",
        "        \"e.g.\": \"eg<abbr>\",\n",
        "        \"i.e.\": \"ie<abbr>\"\n",
        "    }\n",
        "\n",
        "    # Step 1: Temporarily replace abbreviations\n",
        "    for abbr, placeholder in abbreviations.items():\n",
        "        paragraph_text = paragraph_text.replace(abbr, placeholder)\n",
        "\n",
        "    # Step 2: Split sentences using a simple regex\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', paragraph_text.strip())\n",
        "\n",
        "    # Step 3: Restore abbreviations\n",
        "    sentences = [sentence.replace(\"<abbr>\", \".\") for sentence in sentences]\n",
        "\n",
        "    # Return structured sentence objects\n",
        "    return [{\"id\": i, \"text\": sentence.strip()} for i, sentence in enumerate(sentences) if sentence.strip()]\n",
        "\n",
        "def drafting_agent(section_outline, overview):\n",
        "    system_prompt = (\n",
        "        \"You are an academic writer. Your task is to write a well-structured and logically coherent paragraph \"\n",
        "        \"based on the provided section outline, while ensuring it aligns with the overall structure and flow \"\n",
        "        \"outlined in the essay overview. The paragraph should follow academic standards for clarity and precision. \"\n",
        "        \"Ensure that the paragraph remains consistent with the topic and details provided in the outline.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Generate a paragraph based on the following outline and essay overview:\n",
        "\n",
        "    Overview:\n",
        "    {overview}\n",
        "\n",
        "    Section Outline:\n",
        "    {section_outline}\n",
        "\n",
        "    Your response must be formatted as a JSON object with the following structure:\n",
        "    {{\n",
        "      \"text\": \"string\"\n",
        "    }}\n",
        "\n",
        "    - The paragraph should be clear, well-structured, and aligned with the topic and details provided.\n",
        "    - Ensure logical flow and coherence within the paragraph.\n",
        "    - Maintain consistency with the essay's overall structure as outlined in the overview.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def gross_revision_agent(paragraph, thesis, argument, section_outline):\n",
        "    system_prompt = (\n",
        "        \"\"\"You are a philosophy editor specializing in deepening academic writing. \"\n",
        "        \"Your task is to revise the provided paragraph to enhance its philosophical depth, detail, exposition, and clarity. \"\n",
        "        \"Strengthen the argument by expanding key points, improving explanations, and incorporating additional support where necessary. \"\n",
        "        \"Ensure that every claim is well-articulated, logically developed, and contextualized within the broader discussion. \"\n",
        "        \"Focus on increasing precision and depth without altering the intended meaning or introducing unrelated ideas. \"\n",
        "        \"Clarify abstract or ambiguous statements, reinforce logical connections, and provide additional exposition where needed to make the argument more rigorous and comprehensive. \"\n",
        "        \"Maintain an academic tone, ensuring that the paragraph aligns seamlessly with the section’s argument and the overarching thesis of the essay.\"\"\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Revise the following paragraph for deeper philosophical engagement, refining arguments, and adding necessary detail.\n",
        "\n",
        "    Thesis:\n",
        "    {thesis}\n",
        "\n",
        "    Section Outline:\n",
        "    {section_outline}\n",
        "\n",
        "    Supporting Argument:\n",
        "    {argument}\n",
        "\n",
        "    Original Paragraph:\n",
        "    {paragraph}\n",
        "\n",
        "    Your response must be formatted as a JSON object with the following structure:\n",
        "    {{\n",
        "      \"text\": \"string\"\n",
        "    }}\n",
        "\n",
        "    - Ensure the revised paragraph maintains logical coherence with the thesis and section argument.\n",
        "    - Improve depth, precision, and clarity in philosophical reasoning.\n",
        "    - Preserve the intended meaning while enhancing readability and engagement.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def section_instruction_agent(section, thesis, argument):\n",
        "    system_prompt = (\n",
        "        \"You are an academic writing editor. Your task is to analyze a section of a philosophy essay \"\n",
        "        \"and generate paragraph-specific revision instructions. Identify redundancies, improve logical flow, \"\n",
        "        \"and suggest wording adjustments. You may not restructure the section or recommend the addition or \"\n",
        "        \"removal of full paragraphs. Do NOT rewrite the section—only provide structured revision guidance.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following section and generate structured revision instructions for each paragraph.\n",
        "\n",
        "    Thesis:\n",
        "    {thesis}\n",
        "\n",
        "    Argument:\n",
        "    {argument}\n",
        "\n",
        "    Section Title: {section[\"title\"]}\n",
        "\n",
        "    Section Content:\n",
        "    {\" \".join(paragraph[\"text\"] for paragraph in section[\"paragraphs\"])}\n",
        "\n",
        "    Your response must be formatted as a JSON object:\n",
        "    {{\n",
        "      \"revision_instructions\": [\n",
        "        {{\n",
        "          \"id\": \"integer\",\n",
        "          \"instructions\": \"string\"\n",
        "        }}\n",
        "      ]\n",
        "    }}\n",
        "\n",
        "    - Identify redundant ideas across paragraphs.\n",
        "    - Improve logical flow between paragraphs.\n",
        "    - Suggest rewording for clarity and conciseness.\n",
        "    - Do NOT rewrite the section, only provide structured revision guidance.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def paragraph_revision_agent(paragraph, instructions, thesis, argument):\n",
        "    system_prompt = (\n",
        "        \"You are an academic writing editor. Your task is to refine a single paragraph based on structured revision instructions. \"\n",
        "        \"Ensure clarity, conciseness, and logical alignment. Apply the suggested revisions, but do NOT remove the paragraph.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Refine the following paragraph based on the provided revision instructions.\n",
        "\n",
        "    Thesis:\n",
        "    {thesis}\n",
        "\n",
        "    Argument:\n",
        "    {argument}\n",
        "\n",
        "    Revision Instructions:\n",
        "    {instructions}\n",
        "\n",
        "    Original Paragraph:\n",
        "    {paragraph[\"text\"]}\n",
        "\n",
        "    Your response must be formatted as a JSON object:\n",
        "    {{\n",
        "      \"text\": \"string\"\n",
        "    }}\n",
        "\n",
        "    - Implement the suggested improvements while maintaining the paragraph's meaning.\n",
        "    - Improve clarity, conciseness, and logical flow.\n",
        "    - Do NOT remove the paragraph.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def section_refinement_agent(section, thesis, argument):\n",
        "    system_prompt = (\n",
        "        \"You are an academic writing editor specializing in philosophical essays. Your task is to revise the following section \"\n",
        "        \"by removing redundant content, ensuring coherence between paragraphs, and maintaining logical flow. Eliminate unnecessary \"\n",
        "        \"repetition and redundant language to improve the flow of the text while preserving detail, depth and rigor in argumentation.\"\n",
        "        \"Add additional support or exposition that serves to conceptually connect and unify the section into a cohesive whole. \"\n",
        "        \"This is the last step of the revision process, so your final product should be exemplary of excellent academic writing, \"\n",
        "        \"rich philosophical inquiry, and clear and effective communication in the field of academic philosophy.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Refine the following section of a philosophy essay to improve coherence and eliminate redundancy.\n",
        "\n",
        "    Thesis:\n",
        "    {thesis}\n",
        "\n",
        "    Argument:\n",
        "    {argument}\n",
        "\n",
        "    Section Title: {section[\"title\"]}\n",
        "\n",
        "    Section Summary: {section[\"summary\"]}\n",
        "\n",
        "    Section Content:\n",
        "    {section['paragraphs']}\n",
        "\n",
        "    Your response must be formatted as a JSON object with the following structure:\n",
        "    {{\"title\": \"string\",\n",
        "      \"summary\": \"string\",\n",
        "      \"paragraphs\":\n",
        "        {{\n",
        "          \"id\": \"integer\",\n",
        "          \"text\": \"string\"\n",
        "        }}\n",
        "    }}\n",
        "    - Maintain logical flow and academic rigor.\n",
        "    - Ensure each paragraph contributes uniquely to the argument.\n",
        "    - Improve readability by reducing unnecessary repetition.\n",
        "    - Keep the response strictly formatted as JSON.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def citation_insertion_agent(paragraph):\n",
        "    system_prompt = (\n",
        "        \"You are a reference manager specializing in academic philosophy. Your task is to insert parenthetical citations \"\n",
        "        \"of the form (LastName) into the sentences of the given paragraph for the purpose of attributing non-original ideas \"\n",
        "        \"to their owners. Inserting parenthetical references is the ONLY edit you are permitted to make to any sentence. \"\n",
        "        \"For each sentence, if the source is mentioned in the sentence by name, you do not need to edit the sentence. \"\n",
        "        \"The result of your work should be identical to the original sentence apart from the parenthetical citations you add.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Insert appropriate citations into the following paragraph using the provided citation suggestions.\n",
        "\n",
        "    Paragraph:\n",
        "    {paragraph}\n",
        "\n",
        "    Your response must be formatted as a JSON object with the following structure:\n",
        "\n",
        "    {{\n",
        "      \"text\": \"string\"\n",
        "    }}\n",
        "\n",
        "    - The \"text\" field is the full text of the paragraph with citations inserted where appropriate. \"\n",
        "    - Use the format (LastName) for the appropriately attributable entity.\n",
        "    - Do not include any additional information like works or year in the parenthetical citation. ONLY the last name of the identity receiving the attribution should appear in the parenthetical citation.\n",
        "    \"\"\"\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def citation_extraction_agent(paragraph):\n",
        "    system_prompt = (\n",
        "        \"You are a reference extraction assistant. Your task is to extract all parenthetical citations from the provided paragraph.\"\n",
        "        \"and return in a notated aggregated JSON format.\"\n",
        "        \"Your output must conform to JSON structure with no additional text, comments, characters, markdown beginning with { and \"\n",
        "        \"ending with }. You may not deviate from the JSON structure or use alternate keys.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Extract citations from the following paragraph:\n",
        "\n",
        "    {paragraph}\n",
        "\n",
        "    Your response must be formatted as a JSON object with the following structure:\n",
        "\n",
        "   {{\n",
        "      \"works\": [\n",
        "        {{\n",
        "          \"identity\": \"string\",\n",
        "          \"description\": \"string\",\n",
        "          \"relevance\": \"string\"\n",
        "        }}\n",
        "      ]\n",
        "    }}\n",
        "\n",
        "    - The \"identity\" field should the name of the author or entity to whom attribution should be made.\n",
        "    - The \"description\" field should be a brief sentence noting why the attribution was made to the author or entity.\n",
        "    - Only extract unique citations (do not create duplicate entries for the same author or entity).\n",
        "    - Do not add any extra text outside of the JSON object.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def works_cited_agent(paragraph, thesis, abstract):\n",
        "    system_prompt = (\n",
        "        \"You are an academic reference organizer. Your task is to extracted parenthetical citations from a paragraph. Based on \"\n",
        "        \"the textual context and the thesis of the paper from which the paragraph is taken, you will create a works cited entry \"\n",
        "        \"to give attribution to the author of concepts and ideas that influenced the paper from which the paragraph is taken. \"\n",
        "        \"Your output must conform to JSON structure with no additional text, comments, characters, markdown beginning with { and \"\n",
        "        \"ending with }. You may not deviate from the JSON structure or use alternate keys.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    Thesis:\n",
        "    {thesis}\n",
        "\n",
        "    Abstract:\n",
        "    {abstract}\n",
        "\n",
        "    Citation List:\n",
        "    {paragraph}\n",
        "\n",
        "    Your response must be formatted as a JSON object:\n",
        "\n",
        "    {{ works:\n",
        "      [\n",
        "        {{\n",
        "          \"identity\": \"string\",\n",
        "          \"description\": \"string\",\n",
        "          \"relevance\": \"string\"\n",
        "        }},\n",
        "      ]\n",
        "    }}\n",
        "\n",
        "    - The \"identity\" field should the name of the author or entity to whom attribution is made.\n",
        "    - The \"description\" field gives a brief overview of the author or entity and the totality of their work.\n",
        "    - The \"relevance\" field gives a few sentences on how the author or entity\n",
        "    - Standardize the citation formatting for consistency.\n",
        "    - Do not include any extra text outside the JSON object.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def works_cited_aggregation_agent(works_cited):\n",
        "    system_prompt = (\n",
        "        \"You are an academic reference organizer. Your task is to review the following authors and the accompanying notes, which \"\n",
        "        \"were generated automatically based on parenthetical citations. As you can see, there are many repititions and redundancies. \"\n",
        "        \"Distill this list down to unique authors, and combine the description and relevance for each author to create a single \"\n",
        "        \"attribution entry for each author. Your output must conform to JSON structure with no additional text, comments, characters, \"\n",
        "        \"markdown beginning with { and ending with }. The JSON structure output should be flat. You may not deviate from the JSON structure or use alternate keys.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    Citation List:\n",
        "    {works_cited}\n",
        "\n",
        "    Your response must be formatted as a flat JSON object:\n",
        "\n",
        "    {{\n",
        "      {{\n",
        "          \"identity\": \"string\",\n",
        "          \"description\": \"string\",\n",
        "          \"relevance\": \"string\"\n",
        "        }},\n",
        "    }}\n",
        "\n",
        "    - The \"identity\" field should the name of the author or entity to whom attribution is made as 'Last, First'.\n",
        "    - The \"description\" field gives a brief overview of the author or entity and the totality of their work.\n",
        "    - The \"relevance\" field gives a few sentences on how the author or entity\n",
        "    - Standardize the citation formatting for consistency.\n",
        "    - Do not include any extra text outside the JSON object.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(prompt, system_prompt)\n",
        "\n",
        "def abstract_agent(essay_json):\n",
        "    system_prompt = (\n",
        "        \"You are an academic summarizer specializing in philosophy. Your task is to write a concise, well-structured abstract \"\n",
        "        \"that effectively summarizes the entire essay, including the thesis, key arguments, philosophical context, discussion points, and conclusion. \"\n",
        "        \"Ensure the abstract is engaging, clear, and informative while adhering to academic standards.\"\n",
        "    )\n",
        "\n",
        "    # Step 1: Summarize each section separately to reduce input size\n",
        "    section_summaries = []\n",
        "    for section in essay_json[\"sections\"]:\n",
        "        section_prompt = f\"\"\"\n",
        "        Summarize the following section of a philosophy essay:\n",
        "\n",
        "        Section Title: {section['title']}\n",
        "\n",
        "        Section Content:\n",
        "        {section['summary']}\n",
        "\n",
        "        Paragraphs:\n",
        "        {\" \".join(paragraph['text'] for paragraph in section['paragraphs'])}\n",
        "\n",
        "        Your response must be formatted as a JSON object:\n",
        "        {{\n",
        "          \"section_summary\": \"string\"\n",
        "        }}\n",
        "        \"\"\"\n",
        "        summary_response = call_llm(section_prompt, system_prompt)\n",
        "        section_summary = parse_json_with_validation(summary_response).get(\"section_summary\", \"\")\n",
        "        section_summaries.append({\"title\": section[\"title\"], \"summary\": section_summary})\n",
        "\n",
        "    # Step 2: Use section summaries for the final abstract generation\n",
        "    abstract_prompt = f\"\"\"\n",
        "    Below are the key components of a philosophy essay. Your task is to generate a concise abstract.\n",
        "\n",
        "    Thesis:\n",
        "    {essay_json[\"thesis\"]}\n",
        "\n",
        "    Section Summaries:\n",
        "    \"\"\"\n",
        "    for section in section_summaries:\n",
        "        abstract_prompt += f\"Section: {section['title']}\\nSummary: {section['summary']}\\n\\n\"\n",
        "\n",
        "    abstract_prompt += \"\"\"\n",
        "    Your response must be formatted as a JSON object with the following structure:\n",
        "    {\n",
        "      \"abstract\": \"string\"\n",
        "    }\n",
        "\n",
        "    - Ensure the abstract is concise (150-250 words), engaging, and informative.\n",
        "    - Clearly summarize the thesis, major arguments, counterarguments, and philosophical significance.\n",
        "    - Maintain logical coherence and clarity for an academic audience.\n",
        "    \"\"\"\n",
        "\n",
        "    return call_llm(abstract_prompt, system_prompt)\n",
        "\n",
        "def title_generation_agent(abstract):\n",
        "    \"\"\"\n",
        "    Uses an LLM to generate a concise, informative title from an abstract.\n",
        "\n",
        "    Parameters:\n",
        "    - abstract (str): The abstract of the essay.\n",
        "\n",
        "    Returns:\n",
        "    - str: JSON-formatted response containing the title.\n",
        "    \"\"\"\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are an academic writing assistant specialized in generating concise, informative titles. \"\n",
        "        \"Your task is to create a clear, engaging, and academically appropriate title based on the provided abstract. \"\n",
        "        \"The title should summarize the core theme of the abstract while being brief and compelling.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    Topic:\n",
        "    {Topic}\n",
        "\n",
        "    Abstract:\n",
        "    {abstract}\n",
        "\n",
        "    Generate a concise, informative title for this abstract. Ensure the title is:\n",
        "    - No longer than 12 words.\n",
        "    - Academically appropriate and engaging.\n",
        "    - Clearly related to the main theme of the abstract.\n",
        "\n",
        "    Your response must be formatted as a JSON object:\n",
        "    {{\n",
        "      \"title\": \"string\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    response = call_llm(prompt, system_prompt)\n",
        "    return response  # The main function will handle JSON parsing\n",
        "\n",
        "def json_fixing_agent(response_text):\n",
        "    \"\"\"\n",
        "    Uses an LLM to clean and fix malformed JSON structures, ensuring proper formatting and structure.\n",
        "    This function is designed to be called iteratively within a validation loop.\n",
        "    \"\"\"\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are an expert JSON repair agent. You will be given a malformed JSON object. Your task is to clean the text input \"\n",
        "        \"and correct any malformed JSON found in a given text response. The JSON may have any number of errors. You \"\n",
        "        \"must find them and correct them. Your response must contain ONLY valid JSON written with no extra text, explanations, \"\n",
        "        \"or markdown. Output only the text charachters that represent the correct JSON. Your response should start with { and \"\n",
        "        \"end with }.\"\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    The following text contains malformed JSON that may have structural errors or extra text.\n",
        "    Extract and correct the JSON, ensuring it is properly formatted and syntactically valid.\n",
        "\n",
        "    Response to fix:\n",
        "    {response_text}\n",
        "\n",
        "    Return ONLY the corrected JSON.\n",
        "    \"\"\"\n",
        "\n",
        "    fixed_response = call_llm(prompt, system_prompt)\n",
        "\n",
        "    return fixed_response\n",
        "\n",
        "class MaxJsonAttemptsExceededError(Exception):\n",
        "    \"\"\"Raised when JSON parsing fails after the maximum number of attempts.\"\"\"\n",
        "    def __init__(self, attempts, message=\"JSON parsing failed after maximum number of attempts. This is rare, so try again!\"):\n",
        "        self.attempts = attempts\n",
        "        self.message = f\"{message} ({attempts} attempts)\"\n",
        "        super().__init__(self.message)\n",
        "\n",
        "def parse_json_with_validation(response_text):\n",
        "    \"\"\"\n",
        "    Attempts to parse a JSON response by running it through the JSON Fixing Agent iteratively\n",
        "    until it parses successfully or reaches a retry limit.\n",
        "    \"\"\"\n",
        "    global MAX_JSON_ATTEMPTS\n",
        "    attempts = 0\n",
        "    try:\n",
        "      while attempts < MAX_JSON_ATTEMPTS:\n",
        "          try:\n",
        "              # Remove markdown-style code blocks if they exist\n",
        "              response_text = re.sub(r'```json|```', '', response_text).strip()\n",
        "\n",
        "              # Extract JSON block safely (no lookbehind)\n",
        "              json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
        "              if not json_match:\n",
        "                  raise json.JSONDecodeError(\"No valid JSON found\", response_text, 0)\n",
        "\n",
        "              cleaned_json_text = json_match.group(0)\n",
        "              parsed_json = json.loads(cleaned_json_text)\n",
        "\n",
        "              return parsed_json  # Successfully parsed JSON\n",
        "          except json.JSONDecodeError:\n",
        "              print(f\"JSON parsing failed. Running JSON Fixing Agent (attempt {attempts + 1})...\")\n",
        "              response_text = json_fixing_agent(response_text)\n",
        "              attempts += 1\n",
        "\n",
        "      # Raise a custom error after exceeding max attempts\n",
        "      raise MaxJsonAttemptsExceededError(MAX_JSON_ATTEMPTS)\n",
        "    except MaxJsonAttemptsExceededError as e:\n",
        "      print(f\"Error: {e}\")  # Handle the max attempts exceeded error\n",
        "\n",
        "def convert_json_to_plaintext(essay_json):\n",
        "    \"\"\"\n",
        "    Converts the final structured JSON essay into a plain-text readable format.\n",
        "    \"\"\"\n",
        "    plaintext = \"\"\n",
        "    plaintext += f\"{essay_json['title']}\\n\\n\"\n",
        "    plaintext += f\"Abstract\\n{essay_json['abstract']}\\n\\n\"\n",
        "\n",
        "    plaintext += \"Body\\n\\n\"\n",
        "    for section in essay_json['sections']:\n",
        "        plaintext += f\"{section['title']}\\n\\n\"\n",
        "        for paragraph in section['paragraphs']:\n",
        "            plaintext += f\"{paragraph['text']}\\n\\n\"\n",
        "\n",
        "    plaintext += \"Works Cited\\n\\n\"\n",
        "    for philosopher in essay_json['context']['philosophers']:\n",
        "        plaintext += f\"{philosopher['name']}. *{philosopher['work']}*. {philosopher['relevance']}.\\n\"\n",
        "    plaintext += \"\\n\"\n",
        "    for concept in essay_json['context']['concepts']:\n",
        "        plaintext += f\"{concept['name']}. {concept['definition']}. {concept['relevance']}.\\n\"\n",
        "    plaintext += \"\\n\"\n",
        "\n",
        "    return plaintext\n",
        "\n",
        "def save_to_file(filename, content):\n",
        "    \"\"\"Helper function to save content to a file.\"\"\"\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(content)\n",
        "    print(f\"File saved: {filename}\")\n",
        "\n",
        "def convert_json_to_markdown(essay_json):\n",
        "    \"\"\"Converts the essay JSON into Markdown format.\"\"\"\n",
        "    markdown_text = f\"# {essay_json['title']}\\n\\n\"\n",
        "    markdown_text += f\"**Abstract**\\n\\n{essay_json['abstract']}\\n\\n\"\n",
        "\n",
        "    for section in essay_json['sections']:\n",
        "        markdown_text += f\"## {section['title']}\\n\\n\"\n",
        "        for paragraph in section['paragraphs']:\n",
        "            markdown_text += f\"{paragraph['text']}\\n\\n\"\n",
        "\n",
        "    markdown_text += \"### Works Cited\\n\\n\"\n",
        "    for entry in essay_json[\"works_cited\"]:\n",
        "        markdown_text += f\"- **{entry['identity']}**: {entry['description']}\\n  - {entry['relevance']}\\n\"\n",
        "\n",
        "    return markdown_text\n",
        "\n",
        "def convert_json_to_latex(essay_json):\n",
        "    \"\"\"Converts the essay JSON into LaTeX format.\"\"\"\n",
        "    latex_text = r\"\"\"\n",
        "\\title{\"\"\" + essay_json['title'] + r\"\"\"}\n",
        "\\author{}\n",
        "\\date{}\n",
        "\\begin{document}\n",
        "\\maketitle\n",
        "\n",
        "\\section*{Abstract}\n",
        "\"\"\" + essay_json['abstract'] + r\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    for section in essay_json['sections']:\n",
        "        latex_text += f\"\\\\section{{{section['title']}}}\\n\"\n",
        "        for paragraph in section['paragraphs']:\n",
        "            latex_text += paragraph['text'] + \"\\n\\n\"\n",
        "\n",
        "    latex_text += r\"\\section*{Works Cited}\"\n",
        "\n",
        "    for entry in essay_json[\"works_cited\"]:\n",
        "        latex_text += f\"\\n\\\\textbf{{{entry['identity']}}}: {entry['description']}\\n\\n\"\n",
        "        latex_text += f\"\\\\textit{{{entry['relevance']}}}\\n\\n\"\n",
        "\n",
        "    latex_text += r\"\\end{document}\"\n",
        "\n",
        "    return latex_text\n",
        "\n",
        "def compile_tex_to_pdf(tex_filename):\n",
        "    \"\"\"Compiles a .tex file to .pdf using pdflatex.\"\"\"\n",
        "    command = f\"pdflatex -interaction=nonstopmode -output-directory={os.path.dirname(tex_filename)} {tex_filename}\"\n",
        "    try:\n",
        "        subprocess.run(command, shell=True, check=True)\n",
        "        print(f\"PDF compiled: {tex_filename.replace('.tex', '.pdf')}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error compiling LaTeX to PDF: {e}\")\n",
        "\n",
        "def output_essay(essay_json, format_choice, method_choice):\n",
        "    \"\"\"Handles different output formats and methods.\"\"\"\n",
        "\n",
        "    if format_choice == \"plain text\":\n",
        "        text_output = convert_json_to_plaintext(essay_json)\n",
        "        if method_choice == \"display plain text\":\n",
        "            print(text_output)\n",
        "        elif method_choice == \"save txt to file\":\n",
        "            save_to_file(\"essay.txt\", text_output)\n",
        "\n",
        "    elif format_choice == \"markdown\":\n",
        "        markdown_output = convert_json_to_markdown(essay_json)\n",
        "        if method_choice == \"display markdown\":\n",
        "            display(Markdown(markdown_output))\n",
        "        elif method_choice == \"save markdown to txt to file\":\n",
        "            save_to_file(\"essay.md\", markdown_output)\n",
        "\n",
        "    elif format_choice == \"PDF\":\n",
        "        tex_output = convert_json_to_latex(essay_json)\n",
        "        if method_choice == \"save to tex\":\n",
        "            save_to_file(\"essay.tex\", tex_output)\n",
        "        elif method_choice == \"save file\":\n",
        "            tex_filename = \"essay.tex\"\n",
        "            save_to_file(tex_filename, tex_output)\n",
        "            compile_tex_to_pdf(tex_filename)\n",
        "\n",
        "def generate_philosophy_essay(topic):\n",
        "    \"\"\"\n",
        "    Generates a full philosophy essay with caching support.\n",
        "    If the process crashes, it resumes from the last completed step.\n",
        "    \"\"\"\n",
        "\n",
        "    cache = load_cache()\n",
        "    cache[\"topic\"] = topic  # Always store topic in case we need to reset\n",
        "\n",
        "    if \"context\" in cache:\n",
        "        print(\"Using cached context...\")\n",
        "        context = cache[\"context\"]\n",
        "    else:\n",
        "        print(\"Gathering context...\")\n",
        "        context_response = context_agent(topic)\n",
        "        context = parse_json_with_validation(context_response)\n",
        "        cache[\"context\"] = context\n",
        "        save_cache(cache)\n",
        "\n",
        "    if \"thesis\" in cache:\n",
        "        print(\"Using cached thesis...\")\n",
        "        thesis = cache[\"thesis\"]\n",
        "    else:\n",
        "        print(\"Generating thesis...\")\n",
        "        thesis_response = thesis_agent(topic, context)\n",
        "        thesis = parse_json_with_validation(thesis_response)[\"thesis\"]\n",
        "        cache[\"thesis\"] = thesis\n",
        "        save_cache(cache)\n",
        "\n",
        "    if \"arguments\" in cache:\n",
        "        print(\"Using cached arguments...\")\n",
        "        arguments = cache[\"arguments\"]\n",
        "    else:\n",
        "        print(\"Generating arguments...\")\n",
        "        argument_response = argument_agent(thesis)\n",
        "        arguments = parse_json_with_validation(argument_response)\n",
        "        cache[\"arguments\"] = arguments\n",
        "        save_cache(cache)\n",
        "\n",
        "    if \"discussion\" in cache:\n",
        "        print(\"Using cached discussion...\")\n",
        "        discussion = cache[\"discussion\"]\n",
        "    else:\n",
        "        print(\"Generating discussion...\")\n",
        "        discussion_response = discussion_agent(arguments, context)\n",
        "        discussion = parse_json_with_validation(discussion_response)\n",
        "        cache[\"discussion\"] = discussion\n",
        "        save_cache(cache)\n",
        "\n",
        "    if \"overview\" in cache:\n",
        "        print(\"Using cached overview...\")\n",
        "        overview = cache[\"overview\"]\n",
        "    else:\n",
        "        print(\"Creating overview...\")\n",
        "        overview_response = overview_agent(thesis, arguments, context, discussion)\n",
        "        overview = parse_json_with_validation(overview_response)\n",
        "        cache[\"overview\"] = overview\n",
        "        save_cache(cache)\n",
        "\n",
        "    if \"structure\" in cache:\n",
        "        print(\"Using cached structure...\")\n",
        "        structure = cache[\"structure\"]\n",
        "    else:\n",
        "        print(\"Generating essay structure...\")\n",
        "        structure_response = structure_agent(overview)\n",
        "        structure = parse_json_with_validation(structure_response)\n",
        "        cache[\"structure\"] = structure\n",
        "        save_cache(cache)\n",
        "\n",
        "    paragraphs = [p for section in structure[\"sections\"] for p in section[\"paragraphs\"]]\n",
        "\n",
        "    if \"drafted_paragraphs\" in cache:\n",
        "        print(\"Using cached drafted paragraphs...\")\n",
        "        drafted_paragraphs = cache[\"drafted_paragraphs\"]\n",
        "    else:\n",
        "        drafted_paragraphs = run_with_progress(\"Drafting...\", paragraphs, drafting_agent, overview)\n",
        "        cache[\"drafted_paragraphs\"] = drafted_paragraphs\n",
        "        save_cache(cache)\n",
        "\n",
        "    index = 0\n",
        "    for section in structure[\"sections\"]:\n",
        "        for paragraph in section[\"paragraphs\"]:\n",
        "          paragraph = drafted_paragraphs[index]\n",
        "          index += 1\n",
        "\n",
        "    paragraphs = [p for section in structure[\"sections\"] for p in section[\"paragraphs\"]]\n",
        "\n",
        "    if \"revised_paragraphs\" in cache:\n",
        "        print(\"Using cached revised paragraphs...\")\n",
        "        revised_paragraphs = cache[\"revised_paragraphs\"]\n",
        "    else:\n",
        "        revised_paragraphs = run_with_progress(\"Revising...\", paragraphs, gross_revision_agent, thesis, arguments, structure)\n",
        "        cache[\"revised_paragraphs\"] = revised_paragraphs\n",
        "        save_cache(cache)\n",
        "\n",
        "    index = 0\n",
        "    for section in structure[\"sections\"]:\n",
        "        for paragraph in section[\"paragraphs\"]:\n",
        "            paragraph = revised_paragraphs[index]\n",
        "            index += 1\n",
        "\n",
        "    paragraphs = [p for section in structure[\"sections\"] for p in section[\"paragraphs\"]]\n",
        "\n",
        "    if \"refined_sections\" in cache:\n",
        "        print(\"Using cached refined sections...\")\n",
        "        refined_sections = cache[\"refined_sections\"]\n",
        "    else:\n",
        "        refined_sections = run_with_progress(\"Revising for coherence...\", structure[\"sections\"], section_refinement_agent, thesis, arguments)\n",
        "        cache[\"refined_sections\"] = refined_sections\n",
        "        save_cache(cache)\n",
        "\n",
        "    for i, refined_section in enumerate(refined_sections):\n",
        "      structure[\"sections\"][i] = refined_section\n",
        "\n",
        "    paragraphs = [p for section in structure[\"sections\"] for p in section[\"paragraphs\"]]\n",
        "\n",
        "    essay_json = {\n",
        "        \"thesis\": thesis,\n",
        "        \"sections\": structure[\"sections\"],\n",
        "    }\n",
        "\n",
        "    print(\"Generating abstract...\")\n",
        "    if \"abstract\" in cache:\n",
        "        print(\"Using cached abstract...\")\n",
        "        abstract = cache[\"abstract\"]\n",
        "    else:\n",
        "        for section in structure[\"sections\"]:\n",
        "            section[\"paragraphs\"] = [\n",
        "                {\"text\": p[\"text\"]} if (isinstance(p, dict) and \"text\" in p) else {\"text\": p} for p in section[\"paragraphs\"]\n",
        "            ]\n",
        "        abstract_response = abstract_agent(essay_json)\n",
        "        abstract = parse_json_with_validation(abstract_response)[\"abstract\"]\n",
        "        cache[\"abstract\"] = abstract\n",
        "        save_cache(cache)\n",
        "\n",
        "    print(\"Generating title...\")\n",
        "    if \"title\" in cache:\n",
        "        print(\"Using cached title...\")\n",
        "        title = cache[\"title\"]\n",
        "    else:\n",
        "        title_response = title_generation_agent(abstract)\n",
        "        title = parse_json_with_validation(title_response)[\"title\"]\n",
        "        essay_json[\"title\"] = title\n",
        "        cache[\"title\"] = title\n",
        "        save_cache(cache)\n",
        "\n",
        "# Begin DUPLICAted section ===========================\n",
        "\n",
        "    if \"cited_paragraphs\" in cache:\n",
        "        print(\"Using cached cited paragraphs...\")\n",
        "        cited_paragraphs = cache[\"cited_paragraphs\"]\n",
        "    else:\n",
        "        cited_paragraphs = run_with_progress(\"Adding citations...\", paragraphs, citation_insertion_agent)\n",
        "        cache[\"cited_paragraphs\"] = cited_paragraphs\n",
        "        save_cache(cache)\n",
        "\n",
        "    index = 0\n",
        "    for section in structure[\"sections\"]:\n",
        "        for paragraph in section[\"paragraphs\"]:\n",
        "            paragraph = cited_paragraphs[index]\n",
        "            index += 1\n",
        "\n",
        "    paragraphs = [p for section in structure[\"sections\"] for p in section[\"paragraphs\"]]\n",
        "    cache[\"cited_paragraphs\"] = cited_paragraphs\n",
        "    save_cache(cache)\n",
        "\n",
        "    index = 0\n",
        "    for section in structure[\"sections\"]:\n",
        "        for paragraph in section[\"paragraphs\"]:\n",
        "            paragraph[\"text\"] = cited_paragraphs[index][\"text\"]\n",
        "            index += 1\n",
        "\n",
        "    if \"cited_paragraphs\" in cache:\n",
        "        print(\"Using cached cited paragraphs...\")\n",
        "        cited_paragraphs = cache[\"cited_paragraphs\"]\n",
        "    else:\n",
        "        cited_paragraphs = run_with_progress(\"Adding citations to text...\", paragraphs, citation_insertion_agent)\n",
        "        cache[\"cited_paragraphs\"] = cited_paragraphs\n",
        "        save_cache(cache)\n",
        "\n",
        "# END DUPLICATION ===========================\n",
        "\n",
        "    index = 0\n",
        "    for section in structure[\"sections\"]:\n",
        "        for paragraph in section[\"paragraphs\"]:\n",
        "            paragraph = cited_paragraphs[index]\n",
        "            index += 1\n",
        "\n",
        "    paragraphs = [p for section in structure[\"sections\"] for p in section[\"paragraphs\"]]\n",
        "    cache[\"cited_paragraphs\"] = cited_paragraphs\n",
        "    save_cache(cache)\n",
        "\n",
        "    if \"citations\" in cache:\n",
        "        print(\"Using cached citations list...\")\n",
        "        citations = cache[\"citations\"]\n",
        "    else:\n",
        "        citations = run_with_progress(\"Collecting citations...\", paragraphs, works_cited_agent, thesis, abstract)\n",
        "        cache[\"citations\"] = citations\n",
        "        save_cache(cache)\n",
        "\n",
        "    from collections import defaultdict\n",
        "\n",
        "    # Process the citations variable\n",
        "    print(\"Consolidating citations...\")\n",
        "    unique_citations = consolidate_citations(citations)\n",
        "    cache[\"unique_citations\"] = unique_citations\n",
        "    save_cache(cache)\n",
        "\n",
        "    print(\"Essay generation complete!\")\n",
        "    essay_json = {\n",
        "        \"title\": title,\n",
        "        \"thesis\": thesis,\n",
        "        \"context\": context,\n",
        "        \"arguments\": arguments,\n",
        "        \"discussion\": discussion,\n",
        "        \"sections\": structure[\"sections\"],\n",
        "        \"abstract\": abstract,\n",
        "        \"works_cited\": unique_citations\n",
        "    }\n",
        "    cache[\"essay_json\"] = essay_json\n",
        "    save_cache(cache)\n",
        "\n",
        "    return essay_json\n",
        "\n",
        "def consolidate_citations(citations):\n",
        "      unique_citations = {}\n",
        "\n",
        "      for entry in citations:\n",
        "          for work in entry[\"works\"]:\n",
        "              identity = work[\"identity\"]\n",
        "              if identity not in unique_citations:\n",
        "                  unique_citations[identity] = {\n",
        "                      \"identity\": identity,\n",
        "                      \"description\": work[\"description\"],\n",
        "                      \"relevance\": []\n",
        "                  }\n",
        "              unique_citations[identity][\"relevance\"].append(work[\"relevance\"])\n",
        "\n",
        "      # Convert the dictionary back to a list\n",
        "      return list(unique_citations.values())\n",
        "\n",
        "def convert_json_to_markdown(essay_json):\n",
        "    \"\"\"Converts the essay JSON into Markdown format.\"\"\"\n",
        "    markdown_text = f\"# {essay_json['title']}\\n\\n\"\n",
        "    markdown_text += f\"**Abstract**\\n\\n{essay_json['abstract']}\\n\\n\"\n",
        "\n",
        "    for section in essay_json['sections']:\n",
        "        markdown_text += f\"## {section['title']}\\n\\n\"\n",
        "        for paragraph in section['paragraphs']:\n",
        "            markdown_text += f\"{paragraph['text']}\\n\\n\"\n",
        "\n",
        "    markdown_text += \"### Works Cited\\n\\n\"\n",
        "    for entry in essay_json[\"works_cited\"]:\n",
        "        markdown_text += f\"- **{entry['identity']}**: {entry['description']}\\n  - {entry['relevance']}\\n\"\n",
        "\n",
        "    return markdown_text\n",
        "\n",
        "def convert_json_to_latex(essay_json):\n",
        "    \"\"\"\n",
        "    Converts the essay JSON into a properly formatted LaTeX document.\n",
        "\n",
        "    Parameters:\n",
        "    - essay_json (dict): The structured JSON object containing the essay content.\n",
        "\n",
        "    Returns:\n",
        "    - Document: A `pylatex` Document object ready for PDF compilation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize LaTeX document with necessary packages and settings\n",
        "    doc = Document()\n",
        "    doc.preamble.append(NoEscape(r\"\\usepackage[margin=1in]{geometry}\"))  # 1-inch margins\n",
        "    doc.preamble.append(NoEscape(r\"\\usepackage{hyperref}\"))  # Hyperlinks support\n",
        "    doc.preamble.append(NoEscape(r\"\\setlength{\\parindent}{0cm}\"))  # Remove paragraph indentation\n",
        "\n",
        "    # Add title, author, and date\n",
        "    doc.preamble.append(Command('title', essay_json['title']))\n",
        "    doc.preamble.append(Command('author', 'Generated by AI'))\n",
        "    doc.preamble.append(Command('date', NoEscape(r'\\today')))\n",
        "\n",
        "    doc.append(NoEscape(r\"\\maketitle\"))  # Generate the title page\n",
        "\n",
        "    # Abstract Section\n",
        "    doc.append(NoEscape(r\"\\section*{Abstract}\"))\n",
        "    doc.append(NoEscape(essay_json['abstract'] + r\" \\\\\" + \"\\n\\n\"))  # Ensure line break after abstract\n",
        "\n",
        "    # Add sections and content\n",
        "    for section in essay_json['sections']:\n",
        "        with doc.create(Section(section['title'])):\n",
        "            for paragraph in section['paragraphs']:\n",
        "                doc.append(NoEscape(paragraph['text'] + r\"\\\\[1em]\"))\n",
        "\n",
        "    # Works Cited Section\n",
        "    doc.append(NoEscape(r\"\\section*{Works Cited}\"))\n",
        "\n",
        "    for entry in essay_json[\"works_cited\"]:\n",
        "        doc.append(NoEscape(f\"\\\\textbf{{{entry['identity']}}}: {entry['description']} \\\\\\\\[1em]\" + \"\\n\\n\"))\n",
        "        #doc.append(NoEscape(f\"\\\\textit{{{entry['relevance']}}} \\\\\"))  # Italicized relevance + Line break\n",
        "\n",
        "    return doc\n",
        "\n",
        "def compile_tex_to_pdf(doc, output_filename=\"essay\"):\n",
        "    \"\"\"\n",
        "    Compiles a LaTeX document into a PDF and provides a download link in Google Colab.\n",
        "\n",
        "    Parameters:\n",
        "    - doc (Document): A `pylatex` Document object.\n",
        "    - output_filename (str): The name of the output PDF file (without extension).\n",
        "\n",
        "    Output:\n",
        "    - Saves the PDF in the current working directory and provides a download link.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        pdf_filename = f\"{output_filename}.pdf\"\n",
        "        doc.generate_pdf(output_filename, compiler=\"pdflatex\", clean_tex=False)\n",
        "\n",
        "        # Provide a download link in Google Colab\n",
        "        files.download(pdf_filename)\n",
        "        print(f\"PDF compiled successfully: {pdf_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error compiling LaTeX to PDF: {e}\")\n",
        "\n",
        "\n",
        "def output_essay(essay_json, format_choice, method_choice):\n",
        "    \"\"\"\n",
        "    Handles different output formats and methods.\n",
        "\n",
        "    Parameters:\n",
        "    - essay_json (dict): The structured JSON object containing the essay.\n",
        "    - format_choice (str): Output format (\"plain text\", \"markdown\", \"tex\").\n",
        "    - method_choice (str): Output method depending on the format.\n",
        "\n",
        "    Actions:\n",
        "    - Displays or saves the essay in the chosen format.\n",
        "    \"\"\"\n",
        "    if format_choice == \"PDF\" and method_choice == \"display\":\n",
        "      print(\"PDF can only be saved to file. If you'd like a PDF, please change the method to \\\"save_to_file\\\" and try again.\")\n",
        "      return None\n",
        "\n",
        "    if format_choice == \"plain text\":\n",
        "        text_output = convert_json_to_plaintext(essay_json)\n",
        "        if method_choice == \"display plain text\":\n",
        "            print(text_output)\n",
        "        elif method_choice == \"save txt to file\":\n",
        "            save_to_file(\"essay.txt\", text_output)\n",
        "\n",
        "    elif format_choice == \"markdown\":\n",
        "        markdown_output = convert_json_to_markdown(essay_json)\n",
        "        if method_choice == \"display markdown\":\n",
        "            display(Markdown(markdown_output))  # Display Markdown in Jupyter/Colab\n",
        "        elif method_choice == \"save markdown to txt to file\":\n",
        "            save_to_file(\"essay.md\", markdown_output)\n",
        "\n",
        "    elif format_choice == \"PDF\":\n",
        "        tex_output = convert_json_to_latex(essay_json)\n",
        "        compile_tex_to_pdf(tex_output, \"essay\")\n",
        "\n",
        "def save_to_file(filename, content):\n",
        "    \"\"\"\n",
        "    Saves content to a file.\n",
        "\n",
        "    Parameters:\n",
        "    - filename (str): The name of the file to save.\n",
        "    - content (str): The content to write to the file.\n",
        "\n",
        "    Output:\n",
        "    - Saves the content as a file in the current working directory.\n",
        "    \"\"\"\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(content)\n",
        "    print(f\"File saved: {filename}\")\n",
        "\n",
        "def run_with_progress(task_name, items, agent_function, *args):\n",
        "    \"\"\"\n",
        "    Runs an agent function with a dynamic progress bar.\n",
        "\n",
        "    Parameters:\n",
        "    - task_name (str): Name of the task (e.g., \"Processing Sections\", \"Generating Titles\").\n",
        "    - items (list): The list of items to iterate over (e.g., sections, paragraphs).\n",
        "    - agent_function (function): The function to run for each item.\n",
        "    - *args: Additional arguments to pass to the agent function.\n",
        "\n",
        "    Returns:\n",
        "    - list: A list of results from running the agent function on each item.\n",
        "    \"\"\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    with tqdm(total=len(items), desc=task_name, bar_format=\"{l_bar}{bar} {n_fmt}/{total_fmt} items\") as pbar:\n",
        "        for item in items:\n",
        "            results.append(parse_json_with_validation(agent_function(item, *args)))\n",
        "            pbar.update(1)  # Update progress bar\n",
        "\n",
        "    return results\n",
        "\n",
        "cache = load_cache()\n",
        "if \"essay_json\" in cache:\n",
        "    print(\"Using cached essay...\")\n",
        "    essay_json = cache[\"essay_json\"]\n",
        "else:\n",
        "    essay_json = generate_philosophy_essay(Topic)\n",
        "print(\"\")\n",
        "print(\"Outputting essay...\")\n",
        "output_essay(essay_json, format_choice, method_choice)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clear_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp4P3Bv4xS0c",
        "outputId": "769a81bd-bd6d-4491-8e09-ad4b6468f43a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache cleared.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}